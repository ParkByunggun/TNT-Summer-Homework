{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d2308cfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as dsets\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7537e1ab",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./data\\MNIST\\raw\\train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "030ae0c045f94aac8f2de81d5c9ad6fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9912422 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data\\MNIST\\raw\\train-images-idx3-ubyte.gz to ./data\\MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./data\\MNIST\\raw\\train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec23ef85b95141b3b8d3948587fba188",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/28881 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data\\MNIST\\raw\\train-labels-idx1-ubyte.gz to ./data\\MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./data\\MNIST\\raw\\t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44170f5eed9945a897b5350285f3a87c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1648877 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data\\MNIST\\raw\\t10k-images-idx3-ubyte.gz to ./data\\MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./data\\MNIST\\raw\\t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2fa9876dd6c3464f8309b94719208912",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4542 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data\\MNIST\\raw\\t10k-labels-idx1-ubyte.gz to ./data\\MNIST\\raw\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pbg11\\anaconda3\\lib\\site-packages\\torchvision\\datasets\\mnist.py:498: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  ..\\torch\\csrc\\utils\\tensor_numpy.cpp:180.)\n",
      "  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n"
     ]
    }
   ],
   "source": [
    "train_dataset = dsets.MNIST(root='./data', train=True, transform=transforms.ToTensor(), download=True)\n",
    "test_dataset = dsets.MNIST(root='./data', train=False, transform=transforms.ToTensor(), download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2b3ab076",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "94c34131",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 10000)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataset), len(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5a0bc7da",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogisticRegression(torch.nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(LogisticRegression, self).__init__()\n",
    "        self.linear = torch.nn.Linear(input_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        outputs = self.linear(x)\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a226dc23",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 100\n",
    "n_iters = 3000\n",
    "epochs = n_iters / (len(train_dataset) / batch_size)\n",
    "input_dim = 784\n",
    "output_dim = 10\n",
    "lr_rate = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "88f1935d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression(input_dim, output_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "26a4c974",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f2d0363d",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.SGD(model.parameters(), lr=lr_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b8138c5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 100. Loss: 0.8972633481025696. Accuracy: 82.45999908447266.\n",
      "Iteration: 200. Loss: 0.9475050568580627. Accuracy: 82.80000305175781.\n",
      "Iteration: 300. Loss: 0.8912056088447571. Accuracy: 82.83999633789062.\n",
      "Iteration: 400. Loss: 1.0597114562988281. Accuracy: 83.01000213623047.\n",
      "Iteration: 500. Loss: 0.8881968855857849. Accuracy: 83.0999984741211.\n",
      "Iteration: 600. Loss: 1.075577974319458. Accuracy: 83.16000366210938.\n",
      "Iteration: 700. Loss: 0.9424571394920349. Accuracy: 83.33000183105469.\n",
      "Iteration: 800. Loss: 0.8629956841468811. Accuracy: 83.33000183105469.\n",
      "Iteration: 900. Loss: 0.7672645449638367. Accuracy: 83.4800033569336.\n",
      "Iteration: 1000. Loss: 0.914611279964447. Accuracy: 83.62999725341797.\n",
      "Iteration: 1100. Loss: 0.7924309372901917. Accuracy: 83.69999694824219.\n",
      "Iteration: 1200. Loss: 0.8088446259498596. Accuracy: 83.87999725341797.\n",
      "Iteration: 1300. Loss: 0.7317532300949097. Accuracy: 83.93000030517578.\n",
      "Iteration: 1400. Loss: 0.8712180852890015. Accuracy: 84.02999877929688.\n",
      "Iteration: 1500. Loss: 0.8878772854804993. Accuracy: 84.0999984741211.\n",
      "Iteration: 1600. Loss: 0.8663030862808228. Accuracy: 84.19999694824219.\n",
      "Iteration: 1700. Loss: 0.8050279021263123. Accuracy: 84.33999633789062.\n",
      "Iteration: 1800. Loss: 0.7924889922142029. Accuracy: 84.30999755859375.\n",
      "Iteration: 1900. Loss: 0.7723772525787354. Accuracy: 84.4000015258789.\n",
      "Iteration: 2000. Loss: 0.9020111560821533. Accuracy: 84.41999816894531.\n",
      "Iteration: 2100. Loss: 0.8003687858581543. Accuracy: 84.5.\n",
      "Iteration: 2200. Loss: 0.775612473487854. Accuracy: 84.63999938964844.\n",
      "Iteration: 2300. Loss: 0.8248558640480042. Accuracy: 84.75.\n",
      "Iteration: 2400. Loss: 0.7973654866218567. Accuracy: 84.83000183105469.\n",
      "Iteration: 2500. Loss: 0.7639495730400085. Accuracy: 84.87999725341797.\n",
      "Iteration: 2600. Loss: 0.7021524310112. Accuracy: 84.93000030517578.\n",
      "Iteration: 2700. Loss: 0.7979688048362732. Accuracy: 85.05999755859375.\n",
      "Iteration: 2800. Loss: 0.6990333795547485. Accuracy: 85.06999969482422.\n",
      "Iteration: 2900. Loss: 0.735187828540802. Accuracy: 85.22000122070312.\n",
      "Iteration: 3000. Loss: 0.6272640824317932. Accuracy: 85.29000091552734.\n"
     ]
    }
   ],
   "source": [
    "iter = 0\n",
    "for epoch in range(int(epochs)):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        images = Variable(images.view(-1, 28 * 28))\n",
    "        labels = Variable(labels)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        iter+=1\n",
    "        if iter%100==0:\n",
    "            \n",
    "            correct = 0\n",
    "            total = 0\n",
    "            for images, labels in test_loader:\n",
    "                images = Variable(images.view(-1, 28*28))\n",
    "                outputs = model(images)\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total+= labels.size(0)\n",
    "                correct+= (predicted == labels).sum()\n",
    "            accuracy = 100 * correct/total\n",
    "            print(\"Iteration: {}. Loss: {}. Accuracy: {}.\".format(iter, loss.item(), accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1005db9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
